/**
 * Costs & Safety: Orchestrates multiple extractions. Costs depend on which methods (OCR, Vision, etc.) are triggered.
 * Module reference: [Working with PDF and Images](https://aitutorial.dev/rag/working-with-unstructured-data#a-complete-unstructured-data-pipeline)
 * Why: Demonstrates a robust "Router" pattern that dispatches files to the appropriate processor based on MIME type.
 */

import * as fs from "fs";
import * as path from "path";
// In a real app, use 'mime-types' or similar. 
// For this example, we'll use a simple extension check to keep dependencies low for the "Router" demo.
// import * as mime from "mime-types"; 

// Import specific processors from our other examples
import { extractTablesFromPdf } from "./pdf_table_extraction.js";
import { extractImageText } from "./pdf_image_ocr.js";
import { generateImageCaption } from "./pdf_image_captioning.js";
import { PDFProcessor } from "./pdf_processing.js"; // From earlier in the module

/**
 * The Unstructured Pipeline orchestrator
 */
class UnstructuredDataPipeline {
    private pdfProcessor: PDFProcessor;
    private supportedTypes: Record<string, (path: string) => Promise<any>>;

    constructor() {
        this.pdfProcessor = new PDFProcessor();

        // Define routing logic
        this.supportedTypes = {
            '.pdf': (p) => this.processPdf(p),
            '.jpg': (p) => this.processImage(p),
            '.jpeg': (p) => this.processImage(p),
            '.png': (p) => this.processImage(p),
            '.txt': (p) => this.processText(p),
            '.docx': (p) => this.processDocx(p)
        };
    }

    async processDocument(filePath: string): Promise<any> {
        const ext = path.extname(filePath).toLowerCase();

        if (!(ext in this.supportedTypes)) {
            // Fallback or error
            console.warn(`Unsupported file type: ${ext}, skipping.`);
            return null;
        }

        console.log(`Routing ${path.basename(filePath)} to handler for ${ext}...`);
        const processor = this.supportedTypes[ext];
        return processor(filePath);
    }

    async processPdf(filePath: string): Promise<any> {
        // 1. Standard text extraction
        // Cast to any to allow adding dynamic properties like 'tables'
        const result: any = await this.pdfProcessor.processPdf(filePath);

        // 2. Specialized table extraction (Enrichment)
        try {
            console.log("  - Attempting table extraction...");
            const tables = await extractTablesFromPdf(filePath);
            if (tables.length > 0) {
                result.tables = tables;
                result.warnings.push(`Found ${tables.length} tables`);
            }
        } catch (e) {
            console.warn("  - Table extraction failed (optional step):", e);
        }

        return result;
    }

    async processImage(filePath: string): Promise<any> {
        console.log("  - Processing image...");

        // Parallel execution for speed (if API limits allow)
        const [text, caption] = await Promise.all([
            extractImageText(filePath).catch(e => { console.error('OCR failed', e); return ""; }),
            generateImageCaption(filePath).catch(e => { console.error('Caption failed', e); return ""; })
        ]);

        // Combined representation
        return {
            text: text,
            caption: caption,
            method: "hybrid_image_processing",
            confidence: 0.85,
            source: filePath
        };
    }

    async processText(filePath: string): Promise<any> {
        return {
            text: fs.readFileSync(filePath, "utf-8"),
            method: "text_read",
            confidence: 1.0
        };
    }

    async processDocx(filePath: string): Promise<any> {
        // Placeholder for DOCX using 'mammoth' or similar
        return { text: "[DOCX Content Placeholder]", method: "docx", confidence: 0.8 };
    }

    async processBatch(directory: string): Promise<any[]> {
        const results: any[] = [];
        if (!fs.existsSync(directory)) return results;

        const files = fs.readdirSync(directory);
        for (const fileName of files) {
            const filePath = path.join(directory, fileName);
            if (fs.statSync(filePath).isFile()) {
                const result = await this.processDocument(filePath);
                if (result) results.push(result);
            }
        }
        return results;
    }
}

// ---------------------------------------------------------
// Execution Example
// ---------------------------------------------------------
async function main() {
    console.log("--- Unstructured Data Pipeline ---");

    // This runs the full pipeline on all assets generated by previous examples.
    // It routes each file to its specialized handler (Vision, OCR, PDF Parser).
    // Note: The DOCX handler is currently a placeholder for demonstration purposes.

    // Ensure we have data to process
    const dataDir = path.join(process.cwd(), 'src', 'module2', 'data');
    if (!fs.existsSync(dataDir)) {
        console.error("Data directory not found. Run previous examples (pdf_table_extraction, etc.) to generate assets.");
        return;
    }

    const pipeline = new UnstructuredDataPipeline();
    const results = await pipeline.processBatch(dataDir); // Process all files in data dir

    console.log(`\nProcessed ${results.length} documents.`);

    // Check results
    results.forEach((doc, i) => {
        console.log(`\n--- Document ${i + 1} ---`);
        console.log(`Source: ${doc.source || 'Unknown'}`);
        console.log(`Method: ${doc.method}`);
        if (doc.tables) console.log(`Tables Found: ${doc.tables.length}`);
        if (doc.caption) console.log(`Caption: ${doc.caption.substring(0, 50)}...`);
    });
}

// Execute
await main();
